{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization Notebook\n",
    "\n",
    "This notebook visualizes the data preparation results for the CheckDi fake news detection project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create visualization directory\n",
    "os.makedirs('../data/visualization', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared data\n",
    "file_path = '../data/processed/news_prepared.csv'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Data file not found at {file_path}\")\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Loaded {len(df)} records from {file_path}\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_label_distribution(df):\n",
    "    \"\"\"Plot the distribution of real vs fake news\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Count plot\n",
    "    label_counts = df['label'].value_counts()\n",
    "    bars = plt.bar(label_counts.index, label_counts.values, color=['#ff6b6b', '#4ecdc4'])\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)} ({height/len(df)*100:.1f}%)',\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "    \n",
    "    plt.title('Distribution of News Labels', fontsize=16, pad=20)\n",
    "    plt.xlabel('Label', fontsize=14)\n",
    "    plt.ylabel('Count', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    # Add grid for better readability\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/visualization/label_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if 'df' in locals():\n",
    "    plot_label_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_text_length_distribution(df):\n",
    "    \"\"\"Plot the distribution of text lengths\"\"\"\n",
    "    df['headline_length'] = df['cleaned_headline'].astype(str).apply(len)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Histogram\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['headline_length'], bins=50, alpha=0.7, color='#6c5ce7')\n",
    "    plt.title('Distribution of Headline Lengths', fontsize=14)\n",
    "    plt.xlabel('Headline Length (characters)', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Box plot by label\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(data=df, x='label', y='headline_length', \n",
    "                hue='label', palette=['#ff6b6b', '#4ecdc4'], legend=False)\n",
    "    plt.title('Headline Length by Label', fontsize=14)\n",
    "    plt.xlabel('Label', fontsize=12)\n",
    "    plt.ylabel('Headline Length (characters)', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/visualization/text_length_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if 'df' in locals():\n",
    "    plot_text_length_distribution(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordclouds(df):\n",
    "    \"\"\"Generate word clouds for real and fake news\"\"\"\n",
    "    # Try to find a suitable font for Thai text\n",
    "    thai_fonts = [\n",
    "        '/System/Library/Fonts/Thonburi.ttc',  # macOS\n",
    "        '/usr/share/fonts/truetype/tlwg/Garuda.ttf',  # Linux\n",
    "        'C:/Windows/Fonts/Tahoma.ttf',  # Windows\n",
    "        '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'  # Alternative\n",
    "    ]\n",
    "    \n",
    "    font_path = None\n",
    "    for font in thai_fonts:\n",
    "        if os.path.exists(font):\n",
    "            font_path = font\n",
    "            break\n",
    "    \n",
    "    if not font_path:\n",
    "        print(\"Warning: Could not find a suitable font for Thai text. Word clouds may not display correctly.\")\n",
    "    \n",
    "    for label in df['label'].unique():\n",
    "        if pd.notna(label):\n",
    "            # Get text for this label\n",
    "            text = ' '.join(df[df['label'] == label]['cleaned_headline'].dropna())\n",
    "            \n",
    "            if text:\n",
    "                # Generate word cloud with Thai font support\n",
    "                wordcloud_params = {\n",
    "                    'width': 800,\n",
    "                    'height': 400,\n",
    "                    'background_color': 'white',\n",
    "                    'colormap': 'viridis',\n",
    "                    'max_words': 100\n",
    "                }\n",
    "                \n",
    "                # Add font path if found\n",
    "                if font_path:\n",
    "                    wordcloud_params['font_path'] = font_path\n",
    "                \n",
    "                wordcloud = WordCloud(**wordcloud_params).generate(text)\n",
    "                \n",
    "                # Plot\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                plt.axis('off')\n",
    "                plt.title(f'Word Cloud for {label} News', fontsize=16)\n",
    "                \n",
    "                # Save and show\n",
    "                filename = f'../data/visualization/wordcloud_{label.lower()}.png'\n",
    "                plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"No text data available for {label} news\")\n",
    "\n",
    "if 'df' in locals():\n",
    "    generate_wordclouds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_preparation_summary():\n",
    "    \"\"\"Plot a summary of the data preparation process\"\"\"\n",
    "    # Sample data for demonstration\n",
    "    stages = ['Raw Data', 'Text Cleaning', 'Train-Test Split', 'Final Dataset']\n",
    "    counts = [291, 291, 291, 291]  # All the same in our case\n",
    "    train_counts = [0, 0, 232, 232]\n",
    "    test_counts = [0, 0, 59, 59]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Plot bars\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(stages))\n",
    "    \n",
    "    bars1 = ax.bar(index - bar_width/2, train_counts, bar_width, \n",
    "                   label='Training Set', color='#4ecdc4', alpha=0.8)\n",
    "    bars2 = ax.bar(index + bar_width/2, test_counts, bar_width, \n",
    "                   label='Test Set', color='#ff6b6b', alpha=0.8)\n",
    "    \n",
    "    # Add labels\n",
    "    ax.set_xlabel('Data Preparation Stages', fontsize=14)\n",
    "    ax.set_ylabel('Number of Samples', fontsize=14)\n",
    "    ax.set_title('Data Preparation Pipeline', fontsize=16)\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(stages, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            if height > 0:\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{int(height)}',\n",
    "                       ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../data/visualization/data_preparation_pipeline.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_data_preparation_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has generated several visualizations to help understand the prepared data:\n",
    "\n",
    "1. **Label Distribution** - Shows the balance between real and fake news in the dataset\n",
    "2. **Text Length Distribution** - Displays the distribution of headline lengths and compares them between real and fake news\n",
    "3. **Word Clouds** - Visualizes the most common words in real and fake news headlines\n",
    "4. **Data Preparation Pipeline** - Illustrates the steps in the data preparation process\n",
    "\n",
    "All visualizations are saved in the `data/visualization` directory for future reference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}