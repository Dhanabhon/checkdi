{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Notebook for AFNC Dataset\n",
    "\n",
    "This notebook prepares the AFNC dataset for training the fake news detection model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Add the src directory to the path so we can import our modules\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "from src.core.data_preparation import load_and_prepare_data, create_sample_dataset\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if AFNC dataset exists\n",
    "afnc_file = '../data/raw/AFNC_Opendata_export_20250728184932.csv'\n",
    "try:\n",
    "    df = pd.read_csv(afnc_file, nrows=5)\n",
    "    print(f\"AFNC dataset found with columns: {list(df.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"AFNC dataset not found. Looking for sample dataset...\")\n",
    "    try:\n",
    "        df = pd.read_csv('../data/raw/news.csv')\n",
    "        print(\"Sample dataset found.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No dataset found. Creating sample dataset...\")\n",
    "        create_sample_dataset()\n",
    "        df = pd.read_csv('../data/raw/news.csv')\n",
    "        print(\"Sample dataset created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "print(\"Starting data preparation process...\")\n",
    "\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test, label_encoder = load_and_prepare_data()\n",
    "    \n",
    "    print(\"\\nData preparation completed successfully!\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Label classes: {label_encoder.classes_}\")\n",
    "    \n",
    "    # Save the splits for later use\n",
    "    np.save('../data/processed/X_train.npy', X_train)\n",
    "    np.save('../data/processed/X_test.npy', X_test)\n",
    "    np.save('../data/processed/y_train.npy', y_train)\n",
    "    np.save('../data/processed/y_test.npy', y_test)\n",
    "    \n",
    "    # Save the label encoder\n",
    "    import joblib\n",
    "    joblib.dump(label_encoder, '../data/processed/label_encoder.pkl')\n",
    "    \n",
    "    print(\"\\nData splits and label encoder saved to processed data directory\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in data preparation: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the prepared data\n",
    "prepared_data_path = '../data/processed/news_prepared.csv'\n",
    "\n",
    "try:\n",
    "    df_prepared = pd.read_csv(prepared_data_path)\n",
    "    \n",
    "    print(\"Prepared dataset info:\")\n",
    "    print(df_prepared.info())\n",
    "    \n",
    "    print(\"\\nFirst few rows of prepared data:\")\n",
    "    display(df_prepared.head())\n",
    "    \n",
    "    print(\"\\nLabel distribution in prepared data:\")\n",
    "    print(df_prepared['label'].value_counts())\n",
    "    \n",
    "    print(\"\\nExamples of cleaned headlines:\")\n",
    "    for i, headline in enumerate(df_prepared['cleaned_headline'].head(5)):\n",
    "        print(f\"{i+1}. {headline}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Prepared data file not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading prepared data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've:\n",
    "1. Checked for the AFNC dataset or created a sample dataset if needed\n",
    "2. Cleaned and prepared the text data\n",
    "3. Encoded the labels (Real vs Fake news)\n",
    "4. Split the data into training and test sets\n",
    "5. Saved the prepared data and splits for use in model training\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Proceed to the model training notebook to train the fake news detection model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}