{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Phase 2: Model Training Notebook\n",
    "\n",
    "This notebook implements Phase 2 of the CheckDi project - training a WangchanBERTa model for Thai fake news detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"Note: Training on CPU will be slower. Consider using GPU for better performance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prepared data\n",
    "print(\"Loading prepared data...\")\n",
    "\n",
    "try:\n",
    "    # Load splits\n",
    "    X_train = np.load('../data/processed/X_train.npy', allow_pickle=True)\n",
    "    X_test = np.load('../data/processed/X_test.npy', allow_pickle=True)\n",
    "    y_train = np.load('../data/processed/y_train.npy', allow_pickle=True)\n",
    "    y_test = np.load('../data/processed/y_test.npy', allow_pickle=True)\n",
    "    \n",
    "    # Load label encoder\n",
    "    label_encoder = joblib.load('../data/processed/label_encoder.pkl')\n",
    "    \n",
    "    print(f\"✓ Training samples: {len(X_train)}\")\n",
    "    print(f\"✓ Test samples: {len(X_test)}\")\n",
    "    print(f\"✓ Label classes: {label_encoder.classes_}\")\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please run the data preparation notebook first.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "OUTPUT_DIR = \"../models/wangchanberta-finetuned-afnc\"\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16  # Adjust based on GPU memory\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Max sequence length: {MAX_LENGTH}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "print(\"Loading tokenizer and model...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(label_encoder.classes_),\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "print(f\"✓ Model loaded with {model.num_labels} output labels\")\n",
    "print(f\"✓ Model moved to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom dataset class\n",
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "print(\"Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "\n",
    "train_dataset = NewsDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "test_dataset = NewsDataset(X_test, y_test, tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(f\"✓ Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"✓ Test dataset: {len(test_dataset)} samples\")\n",
    "\n",
    "# Test dataset creation\n",
    "sample = train_dataset[0]\n",
    "print(f\"✓ Sample input shape: {sample['input_ids'].shape}\")\n",
    "print(f\"✓ Sample label: {sample['labels']} ({label_encoder.classes_[sample['labels']]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "    }\n",
    "\n",
    "print(\"Evaluation metrics defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_dir=f'{OUTPUT_DIR}/logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=None,  # Disable wandb/tensorboard\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "print(\"Training arguments configured\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Trainer created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "print(\"Note: This may take several minutes to hours depending on your hardware.\")\n",
    "\n",
    "# Train\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"Training runtime: {train_result.metrics['train_runtime']:.2f} seconds\")\n",
    "print(f\"Training samples per second: {train_result.metrics['train_samples_per_second']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Evaluating model on test set...\")\n",
    "\n",
    "eval_result = trainer.evaluate()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Test accuracy: {eval_result['eval_accuracy']:.4f}\")\n",
    "print(f\"Test loss: {eval_result['eval_loss']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed predictions and metrics\n",
    "print(\"Generating detailed evaluation metrics...\")\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "y_true = predictions.label_ids\n",
    "\n",
    "# Classification report\n",
    "target_names = label_encoder.classes_\n",
    "report = classification_report(y_true, y_pred, target_names=target_names, output_dict=True)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/visualization/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save detailed results\n",
    "results = {\n",
    "    'accuracy': report['accuracy'],\n",
    "    'macro_avg': report['macro avg'],\n",
    "    'weighted_avg': report['weighted avg'],\n",
    "    'per_class': {target_names[i]: report[target_names[i]] for i in range(len(target_names))}\n",
    "}\n",
    "\n",
    "# Save results to file\n",
    "import json\n",
    "with open(f'{OUTPUT_DIR}/evaluation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results saved to {OUTPUT_DIR}/evaluation_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model and tokenizer\n",
    "print(\"Saving final model and tokenizer...\")\n",
    "\n",
    "# Save model\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# Save additional artifacts\n",
    "model_info = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'max_length': MAX_LENGTH,\n",
    "    'num_labels': len(label_encoder.classes_),\n",
    "    'label_classes': label_encoder.classes_.tolist(),\n",
    "    'final_accuracy': eval_result['eval_accuracy'],\n",
    "    'training_samples': len(X_train),\n",
    "    'test_samples': len(X_test)\n",
    "}\n",
    "\n",
    "with open(f'{OUTPUT_DIR}/model_info.json', 'w') as f:\n",
    "    json.dump(model_info, f, indent=2)\n",
    "\n",
    "# Also save the label encoder\n",
    "joblib.dump(label_encoder, f'{OUTPUT_DIR}/label_encoder.pkl')\n",
    "\n",
    "print(f\"✓ Model saved to {OUTPUT_DIR}\")\n",
    "print(f\"✓ Model info saved to {OUTPUT_DIR}/model_info.json\")\n",
    "print(f\"✓ Label encoder saved to {OUTPUT_DIR}/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved model with sample predictions\n",
    "print(\"Testing saved model with sample predictions...\")\n",
    "\n",
    "# Load the saved model\n",
    "saved_model = AutoModelForSequenceClassification.from_pretrained(OUTPUT_DIR)\n",
    "saved_tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR)\n",
    "saved_model.to(device)\n",
    "saved_model.eval()\n",
    "\n",
    "# Test samples (mix of real and fake news headlines in Thai)\n",
    "test_samples = [\n",
    "    \"รัฐบาลเปิดเผยแผนพัฒนาเศรษฐกิจในปีหน้า\",  # Real news\n",
    "    \"พบยารักษาโรคเบาหวานใหม่ที่มีประสิทธิภาพสูง\",  # Real news\n",
    "    \"วิทยาศาสตร์ใหม่พบว่ากินใบย่านางช่วยลดน้ำหนักได้ภายใน 1 สัปดาห์\",  # Fake news\n",
    "    \"พบว่าน้ำมันมะพร้าวสามารถรักษาโรคมะเร็งได้ 100%\"  # Fake news\n",
    "]\n",
    "\n",
    "print(\"\\nSample Predictions:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, text in enumerate(test_samples, 1):\n",
    "    # Tokenize\n",
    "    inputs = saved_tokenizer(\n",
    "        text, \n",
    "        return_tensors=\"pt\", \n",
    "        max_length=MAX_LENGTH, \n",
    "        truncation=True, \n",
    "        padding=True\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = saved_model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    predicted_label = label_encoder.classes_[predicted_class]\n",
    "    \n",
    "    print(f\"{i}. Text: {text[:50]}...\")\n",
    "    print(f\"   Prediction: {predicted_label} (Confidence: {confidence:.3f})\")\n",
    "    print(f\"   Probabilities: Real={probabilities[0][1]:.3f}, Fake={probabilities[0][0]:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"✓ Model testing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Phase 2 Training Summary\n",
    "\n",
    "This notebook has completed Phase 2 of the CheckDi project:\n",
    "\n",
    "1. **Model Setup**: Loaded WangchanBERTa for Thai text classification\n",
    "2. **Data Preparation**: Created PyTorch datasets from preprocessed data\n",
    "3. **Training**: Fine-tuned the model on AFNC fake news dataset\n",
    "4. **Evaluation**: Generated comprehensive evaluation metrics\n",
    "5. **Model Saving**: Saved the trained model, tokenizer, and metadata\n",
    "6. **Testing**: Validated the saved model with sample predictions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- The trained model is now ready for use in the Streamlit application\n",
    "- The predictor module will load this saved model for real-time predictions\n",
    "- Consider further fine-tuning with additional data or different hyperparameters\n",
    "\n",
    "### Files Generated\n",
    "\n",
    "- `models/wangchanberta-finetuned-afnc/`: Complete trained model\n",
    "- `models/wangchanberta-finetuned-afnc/model_info.json`: Model metadata\n",
    "- `models/wangchanberta-finetuned-afnc/evaluation_results.json`: Detailed evaluation metrics\n",
    "- `data/visualization/confusion_matrix.png`: Confusion matrix visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}